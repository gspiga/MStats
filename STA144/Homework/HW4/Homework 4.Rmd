---
title: "Homework 4"
author: "Gianni Spiga"
date: '2023-06-06'
output:
  html_document:
    df_print: paged
    theme: flatly
    code_folding: hide
    toc: yes
    toc_float: yes
---

# P1: Problem 1, Chapter 5, page 207

These results are not valid since they are clustering by household instead of phone number and collecting information about all eligible voters. So phone numbers and their respective households are most likely to respond the same. 

# P2: Problem 2, Chapter 5, page 208

## 2. 

### a.

This is a cluster sample because they are handing questionares to all the parents in a selected clinic. The *psu* are the clinics, and the *ssu* are the parents given a questionare. This would be one-stage sampling, since we are sampling the entirity of parents in the clinic.

Assuming clusters are not equal sized, for binary data: 

### b. 

The sampling population is parents who visit specific clinics within a week in Chicago. The sample is representative of the sampling population. 

# P3 Problem 4, Chapter 5, page 208

## a.

This example is a cluster sample since we have a primary sampling unit and a secondary sampling unit, which are the journal and 1988 articles respectively. 

## b. 

```{r}
journal <- read.csv("journal.csv")
journal 

sum_ti <- sum(journal$nonprob)
sum_ti

sum_Mi <- sum(journal$numemp)

ybar_r <- sum_ti / sum_Mi
ybar_r

# Estimated variance to find std error
var_j <- sum((journal$nonprob - ybar_r*journal$numemp)^2) / (nrow(journal) - 1)
var_j

sqrt((1 - 26/1285) * 1/(26*(5.69^2)) * var_j)
```
## c.

While this statement may sound confidence if just observing the mean and the standard error for proportions, courts should proceed with great caution when and gather more evidence due to the large consequence in the risk of statistical error in legal proceedings.

# P4 Problem 11, Chapter 5, page 210

```{r}
N_acc <- 828
n_acc <- 85
acc <- data.frame("Errors" = c(0,1,2,3,4), "Freq" = c(57,22,4,1,1))
acc
```
# P5 Problem 14 Chapter 5, page 211

## a. 

```{r}
ti_smo <- sum(c(316.8, 89.4, 153.3, 540))
Mi_smo <- sum(c(792, 447, 511, 800))
mi_smo <- c(25, 15 , 20 , 40)

Mbar_smo <- Mi_smo / 4

ybar_smo <- ti_smo / Mi_smo
ybar_smo

#s2i_smo <- 1 / (mi_smo - 1) * sum()
#s2r_smo <- var(c(316.8, 89.4, 153.3, 540) - c(792, 447, 511, 800)*ybar_smo)
sec_sum <-
  (1 - mi_smo / c(792, 447, 511, 800)) * c(792, 447, 511, 800) ^ 2


#se_smo <- 1 / (Mi_smo/4)^2 * sqrt((1 - 4/29) * s2r_smo/4)
se_smo <-
  sqrt((1 - 4 / 29) * 1 / (4 * Mbar_smo ^ 2) * sum((
    c(316.8, 89.4, 153.3, 540) - ybar_smo * c(792, 447, 511, 800)
  ) ^ 2) / (4 - 1))
se_smo

# our confidence interval 
cat("Our confidence interval is ")
c(ybar_smo - 1.96 * se_smo,  ybar_smo + 1.96 * se_smo)
```

## b.

```{r}
# find total unbiased estimation by N/n * ti
that_smo <- 29 / 4 * ti_smo
#that_smo

st_smo <-
  1 / (4 - 1) * sum((c(316.8, 89.4, 153.3, 540) - that_smo / 29) ^ 2)
#st_smo

se_that_smo <- 29 * sqrt((1 - 4 / 29) * st_smo / 4)
#se_that_smo

# The 95% CI for the total is the following
c(that_smo - 1.96 * se_that_smo,  that_smo + 1.96 * se_that_smo)
```
## c.

```{r}
N <- 29 # number of schools in the region
n <- 4 # number of sampled schools
Mi <- c(792, 447, 511, 800) # size of sampled schools
mi <- c(25, 15, 20, 40) # number sampled in each school
count_smoker <- c(10, 3, 6, 27) # number of female smokers in the schools

sch <-rep(1:n, mi) # vector for school id
stu <- c(1:25, 1:15, 1:20, 1:40) # vector for female student id in each school
smokr <- rep(c(1, 0,1,0,1,0,1,0), times = c(10, 15, 3, 12, 6, 14, 27, 13))

smoker_df <- data.frame(sch, stu, smokr) 
```

```{r}
# From discussion 10

# Estimate of proportion
p_hat <- sum(Mi*(count_smoker/mi))/sum(Mi)   #same as above
# Standard error for proportion:
M_bar <- mean(Mi)
si2 <- aggregate(smokr~sch, data=smoker_df, FUN=var)$smokr

MSW <- sum(si2*(mi-1))/(sum(mi) - n)   #estimated MSW
#MSW
S2 <- sum((smoker_df$smokr - p_hat)^2)/(sum(mi) - 1)   #estimate S2
#S2
Ra2 <- 1 - MSW/S2   #estimated Ra2
#Ra2

N <- 35   #number of wards at new hospital
M_bar <- mean(Mi)   #estimate the mean ward size by the wards in our sample

C <- 300 #budget
c1 <- 50  #cost of psu
c2 <- 0.5   #cost of ssu

#Guidelines for number of psus and ssus
m_opt <- sqrt((c1/c2)*((M_bar*(N-1))/(M_bar*N-1))*((1-Ra2)/Ra2))
cat("The optimized value of m, the number of SSUs, is", ceiling(m_opt), ".\n")
n_opt <- C/(c1 + c2*m_opt)
cat("The optimized value of n, the number of PSUs, is", ceiling(n_opt), ".")

```

# P6 Problem 16, chapter 5, page 212

## a. 

```{r}
measles <- read.csv("measles.csv")
measles

library(dplyr)

#measles <- measles %>% mutate(returnf = replace(returnf, returnf == 9, 0))
measles <- measles %>% filter(returnf != 9)
 #table(measles$school, measles$returnf)
meas_sum <- measles %>% group_by(school) %>% summarise_each(list(sum))
meas_sum

meas_tab <- table(measles$school, measles$returnf)
#ybar hat
ybh <- meas_tab[,2] / rowSums(meas_tab)
ybh
```
## b. 
$$
w_{ij} = \frac{NM_i}{nm_i} \ (5.19)
$$

```{r}
# Correct
# Mi/mi 
Movm = unique(measles$Mitotal) / rowSums(meas_tab)

#N/n = 46/10
Novn <-  46/10

wij <- Movm * Novn
wij
```
## c.

```{r}
# From wrong problem
# ti = sum Mi/mi yij = Mi ybar_i
ti <- unique(measles$Mitotal) * ybh

ybh_r <- sum(ti) / sum(unique(measles$Mitotal))
ybh_r

sum(unique(measles$Mitotal) * ybh) / sum(unique(measles$Mitotal)) * 100

Mbar <-  sum(unique(measles$Mitotal)) / length(unique(measles$Mitotal))
Mbar

# Using formula 5.29
#sr <-
  #1 / (10 - 1) * (ybh_r * sum(unique(measles$Mitotal)) - ybh * sum(unique(measles$Mitotal)
  #sum())^2)
#sr
#sr
#SE_ybhr <- 1 / Mbar * (1 - 1/Novn) * 
```
# P7 Problem 9, Chapter 6, page 269

## a.

```{r}
states <- read.csv("statepps.csv")
states

### For land area
set.seed(123)
cumsumm_states <- cumsum(states$landarea)

# Create range, LB and UB
range_df <- data.frame(cumsumm_states -(states$landarea - 1), cumsumm_states)

# Sample with replacement
states_samp <- sample(1:sum(states$landarea), size = 10, replace = TRUE)
#states_samp

samp_clust <- c()
for (i in 1:10){
  x <- which(states_samp[i] > range_df[,1] & states_samp[i] < range_df[,2])
  samp_clust <- c(samp_clust, x)
}

# These are our chosen samples
states[samp_clust,]

#psi_i
psi_vector <- states$landarea / sum(states$landarea)
psi_vector[samp_clust]
```

## b. 

```{r}
### For population
set.seed(456)
cumsumm_states <- cumsum(states$pop2019)

# Create range, LB and UB
range_df <- data.frame(cumsumm_states -(states$pop2019 - 1), cumsumm_states)

# Sample with replacement
states_samp <- sample(1:sum(states$pop2019), size = 10, replace = TRUE)
#states_samp

samp_clust <- c()
for (i in 1:10){
  x <- which(states_samp[i] > range_df[,1] & states_samp[i] < range_df[,2])
  samp_clust <- c(samp_clust, x)
}

# These are our chosen samples
states[samp_clust,]

#psi_i
psi_vector <- states$pop2019 / sum(states$pop2019)
psi_vector[samp_clust] 
```
## c. 

Given our randomness, the one noticeable state that is shows up in both sample is Texas, which makes sense given its large size and large population. 

# P8: Problem 10, chapter 6, page 269 

## a.

$$
\hat{t}_{\psi} = \frac{1}{n}\sum_{i \in R} \frac{t_i}{\psi_i} \\
\hat{V}(\hat{t}_{\psi}) = \frac{1}{n} \frac{1}{n- 1}\sum_{i \in R} \left(\frac{t_i}{\psi_i} - \hat{t}_{\psi}\right)^2
$$

```{r}
that_psi = 1/10 * sum(states[samp_clust,]$counties / psi_vector[samp_clust])
ceiling(that_psi)

est_var_that_psi= (1 /10) * (1/9) *sum((states[samp_clust,]$counties / psi_vector[samp_clust] - that_psi)^2)
sqrt(est_var_that_psi)

# True value
sum(states$counties)
```
It seems that our estimate is an over estimate of the number of counties by about 1 thousand over. Just a little over one unit of standard error above.  

## b. 

```{r}
# Let's see Tom's SRS
#tom_samp <- sample(1:nrow(states), size = 10, replace = FALSE)
tom_samp <- samp_clust


tom_total <- nrow(states) / 10 * sum(states[tom_samp,]$counties)
tom_total

se_tom = 51* sqrt((1 - 10/51) * var(states[tom_samp,]$counties) / 10)
se_tom
```

Tom's estimated total, 4855, is much farther from the population total (3143 counties) and a smaller standard error. Tom's estimator is biased for the population total since we are assuming without replacement in SRS.   