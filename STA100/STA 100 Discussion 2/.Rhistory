clu8 = bmi_sort[7001:7100],
clu9 = bmi_sort[8001:8100]
)
head(clusters9)
# The rest of the data is not needed.
#For each of the 9 clusters, compute the mean BMI and variance (within variation).
mean_clust9 <- sapply(clusters9, mean)
mean_clust9
# individual variances
sapply(clusters9, var)
SSW <-
sum((99 * sapply(clusters9, var)) ^ 2) # multiply by n-1=99 to correct for sum of squares
cat("The sum of squares within (SSW) is", SSW, "\n")
#Compute the variance of the cluster means (between variation)
# Solving for SSB
SSB <- sum((mean_clust9 - mean(mean_clust9)) ^ 2)
cat("The sum of squares between (SSB) is", SSB, "\n")
SSTO <- SSB + SSW
M <- nrow(clusters9)
ICC <- 1 - ((M / (M - 1)) * (SSW / SSTO))
ICC
S2 <- SSTO / (M * ncol(clusters9) - 1)
S2
MSW <-  SSW / (ncol(clusters9) * (M - 1))
MSW
R2a <- 1 - MSW / S2
cat("The adjusted R^2 is ", R2a)
set.seed(144)
bmi_shuf <- sample(bmi)
clusters9_rand <- data.frame(
clu1 = bmi_shuf[1:100],
clu2 = bmi_shuf[1001:1100],
clu3 = bmi_shuf[2001:2100],
clu4 = bmi_shuf[3001:3100],
clu5 = bmi_shuf[4001:4100],
clu6 = bmi_shuf[5001:5100],
clu7 = bmi_shuf[6001:6100],
clu8 = bmi_shuf[7001:7100],
clu9 = bmi_shuf[8001:8100]
)
clusters9_rand
#For each of the 9 clusters, compute the mean BMI and variance (within variation).
mean_clust9 <- sapply(clusters9_rand, mean)
mean_clust9
# Variance of each cluster
sapply(clusters9_rand, var)
SSW <-
sum((99 * sapply(clusters9_rand, var)) ^ 2) # mutiply by n-1=99 to correct for sum of squares
cat("The sum of squares within (SSW) is", SSW , "\n")
#Compute the variance of the cluster means (between variation)
# Solving for SSB
SSB <- sum((mean_clust9 - mean(mean_clust9)) ^ 2)
cat("The sum of squares between (SSB) is", SSB, "\n")
SSTO <- SSB + SSW
#M <- nrow(clusters9_rand)
ICC <- 1 - ((M / (M - 1)) * (SSW / SSTO))
cat("The ICC is ", ICC ,"\n")
S2 <- SSTO / (M * ncol(clusters9_rand) - 1)
S2
MSW <-  SSW / (ncol(clusters9_rand) * (M - 1))
MSW
R2a <- 1 - MSW / S2
cat("The adjusted R^2 is ", R2a)
# Start with the original nhanes dataset (without missing data removed).
nhanes1 <- read.csv("nhanes.csv", na = ".")
# Remove just the missing data for BMI. We are only interested in BMI for this problem so missing data elsewhere is fine. You should still have over 8000 observations in the dataset.
bmi <- nhanes1$bmxbmi %>% na.omit()
# Order by BMI (lowest to highest)
bmi_sort <- sort(bmi)
# Make 9 clusters, Cluster 1: 1-100, Cluster 2: 1001-1100, ..., Cluster 9: 8001-8100 where these indices are by the ordered BMI. Note that these are not samples from clusters, but the clusters themselves.
clusters9 <- data.frame(
clu1 = bmi_sort[1:100],
clu2 = bmi_sort[1001:1100],
clu3 = bmi_sort[2001:2100],
clu4 = bmi_sort[3001:3100],
clu5 = bmi_sort[4001:4100],
clu6 = bmi_sort[5001:5100],
clu7 = bmi_sort[6001:6100],
clu8 = bmi_sort[7001:7100],
clu9 = bmi_sort[8001:8100]
)
head(clusters9)
# The rest of the data is not needed.
#For each of the 9 clusters, compute the mean BMI and variance (within variation).
mean_clust9 <- sapply(clusters9, mean)
mean_clust9
# individual variances
sapply(clusters9, var)
SSW <-
sum((99 * sapply(clusters9, var)) ^ 2) # multiply by n-1=99 to correct for sum of squares
cat("The sum of squares within (SSW) is", SSW, "\n")
#Compute the variance of the cluster means (between variation)
# Solving for SSB
SSB <- sum((mean_clust9 - mean(mean_clust9)) ^ 2)
cat("The sum of squares between (SSB) is", SSB, "\n")
SSTO <- SSB + SSW
M <- nrow(clusters9)
ICC <- 1 - ((M / (M - 1)) * (SSW / SSTO))
ICC
S2 <- SSTO / (M * ncol(clusters9) - 1)
S2
MSW <-  SSW / (ncol(clusters9) * (M - 1))
MSW
R2a <- 1 - MSW / S2
cat("The adjusted R^2 is ", R2a)
clusters9
as.vector(clusers9)
as.vector(clusters9)
var(clusters9)
as.vector(t(clusters9))
var(as.vector(t(clusters9)))
var(as.vector(t(clusters9))) * (M * ncol(clusters9) - 1)
var(as.vector(t(clusters9))) * (M * ncol(clusters9) - 2)
mean(as.vector(t(clusters9)))
clusters9 - ybar_u
### SSTO BY HAND
ybar_u <- mean(as.vector(t(clusters9)))
clusters9 - ybar_u
colsums(clusters9 - ybar_u)
colSums(clusters9 - ybar_u)
sum(colSums(clusters9 - ybar_u))
sum(colSums((clusters9 - ybar_u)^2))
mean(mean_clust9)
ybar_u
#Compute the variance of the cluster means (between variation)
# Solving for SSB
SSB <- sum( nrow(clusters) * (mean_clust9 - mean(mean_clust9)) ^ 2)
#Compute the variance of the cluster means (between variation)
# Solving for SSB
SSB <- sum( nrow(clusters9) * (mean_clust9 - mean(mean_clust9)) ^ 2)
cat("The sum of squares between (SSB) is", SSB, "\n")
SSW
sum((clusters9 - mean_clust9)^2)
clusters9 - mean_clust9
clusters9
mean_clust9
12.40 - 13.6262
colSums((clusters9 - mean_clust9)^2)
mean_clust9
cat("The sum of squares within (SSW) is", SSW, "\n")
cat("The sum of squares between (SSB) is", SSB, "\n")
clusters9[1]
clusters9[1] - mean_clust9[1]
(clusters9[1] - mean_clust9[1])62
(clusters9[1] - mean_clust9[1])^2
sum((clusters9[1] - mean_clust9[1])^2)
sum((clusters9[2] - mean_clust9[2])^2)
sum((clusters9[3] - mean_clust9[3])^2)
sum((clusters9 - mean_clust9)^2)
sum((clusters9 - c(mean_clust9))^2)
sum((t(clusters9) - c(mean_clust9))^2)
sum((clusters9 - t(mean_clust9))^2)
sum((t(clusters9) - mean_clust9)^2)
#Compute the variance of the cluster means (between variation)
# Solving for SSB
SSB <- sum( nrow(clusters9) * (mean_clust9 - mean(mean_clust9)) ^ 2)
cat("The sum of squares between (SSB) is", SSB, "\n")
SSW <-
sum((t(clusters9) - mean_clust9)^2) # multiply by n-1=99 to correct for sum of squares
cat("The sum of squares within (SSW) is", SSW, "\n")
#Compute the variance of the cluster means (between variation)
# Solving for SSB
SSB <- sum( nrow(clusters9) * (mean_clust9 - mean(mean_clust9)) ^ 2)
cat("The sum of squares between (SSB) is", SSB, "\n")
SSTO <- SSB + SSW
SSTO <- sum((clusters9 - ybar_u)^2)
SSTO
cat("The adjusted R^2 is ", R2a)
# Start with the original nhanes dataset (without missing data removed).
nhanes1 <- read.csv("nhanes.csv", na = ".")
# Remove just the missing data for BMI. We are only interested in BMI for this problem so missing data elsewhere is fine. You should still have over 8000 observations in the dataset.
bmi <- nhanes1$bmxbmi %>% na.omit()
# Order by BMI (lowest to highest)
bmi_sort <- sort(bmi)
# Make 9 clusters, Cluster 1: 1-100, Cluster 2: 1001-1100, ..., Cluster 9: 8001-8100 where these indices are by the ordered BMI. Note that these are not samples from clusters, but the clusters themselves.
clusters9 <- data.frame(
clu1 = bmi_sort[1:100],
clu2 = bmi_sort[1001:1100],
clu3 = bmi_sort[2001:2100],
clu4 = bmi_sort[3001:3100],
clu5 = bmi_sort[4001:4100],
clu6 = bmi_sort[5001:5100],
clu7 = bmi_sort[6001:6100],
clu8 = bmi_sort[7001:7100],
clu9 = bmi_sort[8001:8100]
)
head(clusters9)
# The rest of the data is not needed.
#For each of the 9 clusters, compute the mean BMI and variance (within variation).
mean_clust9 <- sapply(clusters9, mean)
mean_clust9
# individual variances
sapply(clusters9, var)
SSW <-
sum((t(clusters9) - mean_clust9)^2) # multiply by n-1=99 to correct for sum of squares
cat("The sum of squares within (SSW) is", SSW, "\n")
#Compute the variance of the cluster means (between variation)
# Solving for SSB
SSB <- sum( nrow(clusters9) * (mean_clust9 - mean(mean_clust9)) ^ 2)
cat("The sum of squares between (SSB) is", SSB, "\n")
# SSTO
ybar_u <- mean(as.vector(t(clusters9)))
SSTO <- sum((clusters9 - ybar_u)^2)
M <- nrow(clusters9)
ICC <- 1 - ((M / (M - 1)) * (SSW / SSTO))
ICC
S2 <- SSTO / (M * ncol(clusters9) - 1)
S2
MSW <-  SSW / (ncol(clusters9) * (M - 1))
MSW
R2a <- 1 - MSW / S2
cat("The adjusted R^2 is ", R2a)
SSW <-
sum((t(clusters9_rand) - mean_clust9)^2)
cat("The sum of squares within (SSW) is", SSW, "\n")
#For each of the 9 clusters, compute the mean BMI and variance (within variation).
mean_clust9 <- sapply(clusters9_rand, mean)
mean_clust9
# Variance of each cluster
sapply(clusters9_rand, var)
SSW <-
sum((t(clusters9_rand) - mean_clust9)^2)
cat("The sum of squares within (SSW) is", SSW, "\n")
set.seed(145)
bmi_shuf <- sample(bmi)
clusters9_rand <- data.frame(
clu1 = bmi_shuf[1:100],
clu2 = bmi_shuf[1001:1100],
clu3 = bmi_shuf[2001:2100],
clu4 = bmi_shuf[3001:3100],
clu5 = bmi_shuf[4001:4100],
clu6 = bmi_shuf[5001:5100],
clu7 = bmi_shuf[6001:6100],
clu8 = bmi_shuf[7001:7100],
clu9 = bmi_shuf[8001:8100]
)
clusters9_rand
#For each of the 9 clusters, compute the mean BMI and variance (within variation).
mean_clust9 <- sapply(clusters9_rand, mean)
mean_clust9
# Variance of each cluster
sapply(clusters9_rand, var)
SSW <-
sum((t(clusters9_rand) - mean_clust9)^2)
cat("The sum of squares within (SSW) is", SSW, "\n")
#Compute the variance of the cluster means (between variation)
# Solving for SSB
SSB <- sum(nrow(clusters9_rand) * (mean_clust9 - mean(mean_clust9)) ^ 2)
cat("The sum of squares between (SSB) is", SSB, "\n")
# SSTO
ybar_u <- mean(as.vector(t(clusters9_rand)))
SSTO <- sum((clusters9_rand - ybar_u)^2)
#M <- nrow(clusters9_rand)
ICC <- 1 - ((M / (M - 1)) * (SSW / SSTO))
cat("The ICC is ", ICC ,"\n")
S2 <- SSTO / (M * ncol(clusters9_rand) - 1)
S2
MSW <-  SSW / (ncol(clusters9_rand) * (M - 1))
MSW
R2a <- 1 - MSW / S2
cat("The adjusted R^2 is ", R2a)
cat("The total variance is",S2,"\n")
set.seed(145)
bmi_shuf <- sample(bmi)
clusters9_rand <- data.frame(
clu1 = bmi_shuf[1:100],
clu2 = bmi_shuf[1001:1100],
clu3 = bmi_shuf[2001:2100],
clu4 = bmi_shuf[3001:3100],
clu5 = bmi_shuf[4001:4100],
clu6 = bmi_shuf[5001:5100],
clu7 = bmi_shuf[6001:6100],
clu8 = bmi_shuf[7001:7100],
clu9 = bmi_shuf[8001:8100]
)
clusters9_rand
#For each of the 9 clusters, compute the mean BMI and variance (within variation).
mean_clust9 <- sapply(clusters9_rand, mean)
mean_clust9
# Variance of each cluster
sapply(clusters9_rand, var)
SSW <-
sum((t(clusters9_rand) - mean_clust9)^2)
cat("The sum of squares within (SSW) is", SSW, "\n")
#Compute the variance of the cluster means (between variation)
# Solving for SSB
SSB <- sum(nrow(clusters9_rand) * (mean_clust9 - mean(mean_clust9)) ^ 2)
cat("The sum of squares between (SSB) is", SSB, "\n")
# SSTO
ybar_u <- mean(as.vector(t(clusters9_rand)))
SSTO <- sum((clusters9_rand - ybar_u)^2)
#M <- nrow(clusters9_rand)
ICC <- 1 - ((M / (M - 1)) * (SSW / SSTO))
cat("The ICC is ", ICC ,"\n")
S2 <- SSTO / (M * ncol(clusters9_rand) - 1)
cat("The total variance is",S2,"\n")
MSW <-  SSW / (ncol(clusters9_rand) * (M - 1))
cat("The MSW is", MSW, "\n")
R2a <- 1 - MSW / S2
cat("The adjusted R^2 is", R2a)
expected_primary_turnout
# Total voters in District 1
district1 <- 86,044
# Total voters in District 1
district1 <- 86044
# From elections 2016 and 2020 respectively, after district voting measure in 2012
past_years_primary_turnout <- c(25250, 30202)
# In order to estimate voter turnout, we will take average of the two years
expected_primary_turnout <- mean(past_years_primary_turnout)
expected_primary_turnout
expected_primary_turnout_prop
# Total voters in District 1
district1_total <- 86044
# From elections 2016 and 2020 respectively, after district voting measure in 2012
past_years_primary_turnout <- c(25250, 30202)
# In order to estimate voter turnout, we will take average of the two years
expected_primary_turnout <- mean(past_years_primary_turnout)
expected_primary_turnout
# Proportion of expected turnout of voters for primary election
expected_primary_turnout_prop <- expected_primary_turnout_prop / district1_total
# Total voters in District 1
district1_total <- 86044
# From elections 2016 and 2020 respectively, after district voting measure in 2012
past_years_primary_turnout <- c(25250, 30202)
# In order to estimate voter turnout, we will take average of the two years
expected_primary_turnout <- mean(past_years_primary_turnout)
expected_primary_turnout
# Proportion of expected turnout of voters for primary election
expected_primary_turnout_prop <- expected_primary_turnout / district1_total
expected_primary_turnout_prop
win_number
# To calculate win number, we need to simple majority
win_number <- (expected_primary_turnout * 0.5) + 1
win_number
win_number_safer <- (expected_primary_turnout * 0.55) + 1
win_number_safer
win_number_safer <- ceiling((expected_primary_turnout * 0.55) + 1)
win_number_safer
# Assuming District 1 is homogenous with other districts (there is no district with some skewed number of a certain demographic)
district1_males <- district1 * 0.4958
district1_females <- district * 0.5042
# Assuming District 1 is homogenous with other districts (there is no district with some skewed number of a certain demographic)
district1_males <- district1 * 0.4958
district1_females <- district1 * 0.5042
district1_males
district1_females
# Assuming District 1 is homogenous with other districts (there is no district with some skewed number of a certain demographic)
district1_males <- ceiling(district1 * 0.4958)
district1_females <- ceiling(district1 * 0.5042)
district1_males
district1_females
age_18_to_25_prop <- 0.8033 - 0.7297
age_18_to_25_district1 <- age_18_to_25_prop * district1
age_18_to_25_district1
ceiling(age_18_to_25_district1)
# Estimated number of voters in district 1 between age 18 and 25
cat(ceiling(age_18_to_25_district1), "voters")
# Assuming District 1 is homogenous with other districts (there is no district with some skewed number of a certain demographic)
district1_males <- ceiling(district1 * 0.4958)
district1_females <- ceiling(district1 * 0.5042)
cat(district1_males, "voters are male")
cat(district1_females, "voters are female")
# Assuming District 1 is homogenous with other districts (there is no district with some skewed number of a certain demographic)
district1_males <- ceiling(district1 * 0.4958)
district1_females <- ceiling(district1 * 0.5042)
cat(district1_males, "voters are male \n")
cat(district1_females, "voters are female")
age_18_to_25_prop <- 0.8033 - 0.7297
age_18_to_25_district1 <- age_18_to_25_prop * district1
# Estimated number of voters in district 1 between age 18 and 25
cat(ceiling(age_18_to_25_district1), "voters between 18 and 25")
win_number_safer <- ceiling((expected_primary_turnout * 0.55) + 1)
win_number_safer
age_25_to_34_district1
age_25_to_34_prop <- 0.138
age_25_to_34_district1 <- age_25_to_34_prop * district1
age_25_to_34_district1
age_18_to_25_prop <- 0.8033 - 0.7297
age_18_to_25_district1 <- age_18_to_25_prop * district1
# Estimated number of voters in district 1 between age 18 and 25
cat(ceiling(age_18_to_25_district1), "voters between 18 and 25")
age_25_to_34_prop <- 0.138
age_25_to_34_district1 <- age_25_to_34_prop * district1
age_25_to_34_district1
cat(ceiling(age_18_to_25_district1), "voters between 18 and 25")
cat(ceiling(age_25_to_34_district1), "voters between 18 and 25")
age_18_to_25_prop <- 0.8033 - 0.7297
age_18_to_25_district1 <- age_18_to_25_prop * district1
# Estimated number of voters in district 1 between age 18 and 25
cat(ceiling(age_18_to_25_district1), "voters between 18 and 25")
age_25_to_34_prop <- 0.138
age_25_to_34_district1 <- age_25_to_34_prop * district1
cat(ceiling(age_25_to_34_district1), "voters between 18 and 25")
# Estimated number of voters in district 1 between age 18 and 25
cat(ceiling(age_18_to_25_district1), "voters between 18 and 25 \n")
age_18_to_25_prop <- 0.8033 - 0.7297
age_18_to_25_district1 <- age_18_to_25_prop * district1
# Estimated number of voters in district 1 between age 18 and 25
cat(ceiling(age_18_to_25_district1), "voters between 18 and 25 \n")
age_25_to_34_prop <- 0.138
age_25_to_34_district1 <- age_25_to_34_prop * district1
cat(ceiling(age_25_to_34_district1), "voters between 18 and 25")
hispanic_latino_prop <- 0.2483
hispanic_latino_district1 <- district1 * hispanic_latino_prop
hispanic_latino_prop <- 0.2483
hispanic_latino_district1 <- district1 * hispanic_latino_prop
hispanic_latino_district1
hispanic_latino_prop <- 0.2483
hispanic_latino_district1 <- district1 * hispanic_latino_prop
ceiling(hispanic_latino_district1)
district1
cat(ceiling(hispanic_latino_district1), "voters between 25 and 34")
# Assuming District 1 is homogenous with other districts (there is no district with some skewed number of a certain demographic)
district1_males <- ceiling(district1 * 0.4958)
district1_females <- ceiling(district1 * 0.5042)
cat(district1_males, "voters are male \n")
cat(district1_females, "voters are female")
install.packages("rmarkdown")
install.packages("rmarkdown")
library(rmarkdown)
render("estimating_win_number.Rmd", "pdf_document")
remove.packages('xfun')
install.packages('xfun')
install.packages("xfun")
render("estimating_win_number.Rmd", "pdf_document")
install.packages("xfun")
install.packages("xfun")
render("estimating_win_number.Rmd", "pdf_document")
remove.packages('xfun')
install.packages("tinytex")
install.packages("tinytex")
remove.packages("xfun")
install.packages("xfun")
install.packages("xfun")
install.packages("Rtools")
.libsPaths()
libPaths()
.libPaths()
remove.packages("xfun")
install.packages("xfun")
install.packages("xfun")
median(c(65, 66, 67, 66, 67, 70, 67, 70, 71, 68))
print("hello world")
patients101 <- read.csv("patients101.csv")
patients101
setwd("C:/Users/Gianni/Documents/Github/MStats/STA100/STA 100 Discussion 2")
patients101 <- read.csv("patients101.csv")
getwd()
patients101 <- read.csv("patients101.csv")
patients101
# a.)
# print("hellop world")
mean(patients101[,3])
# h.)
aggregate(weight ~ marriage, data = patients101, mean)
# Reading in my data, they are in the same folder as my R markdown on my system
patients101 <- read.csv("patients101.csv")
patients101
# This is a comment, by adding a '#' in code, you can tell R to basically "skip" this line
# Commenting is very advantageous and a habit I highly recommend forming early, as it will allow you
# to document all your code, and keep track of what you were doing when you revisit code in the future
# a.)
# print("hello world")
# Either way here works, I like the '$'
mean(patients101[,3])
mean(patients101$sysBP)
# b.)
sd(patients101$sysBP)
# c.)
mean(patients101$weight)
# d. )
mean(patients101$height)
# e.)
# The aggregate function allows us to apply a measure of our choosing to subsets of our data, very powerful
aggregate(weight ~ gender, data = patients101, mean)
# f.)
aggregate(height ~ gender, data = patients101, sd)
# g.)
# height "by" marriage,
aggregate(weight ~ marriage, data = patients101, length)
# h.)
aggregate(weight ~ marriage, data = patients101, mean)
head(patients101, 10) # The head function allows me to preview first 10 rows
# Either way here works, I like the '$'
mean(patients101[, 3])
# Reading in my data, they are in the same folder as my R markdown on my system
patients101 <- read.csv("patients101.csv")
head(patients101, 10) # The head function allows me to preview first 10 rows
# This is a comment, by adding a '#' in code, you can tell R to basically "skip" this line
# Commenting is very advantageous and a habit I highly recommend forming early, as it will allow you
# to document all your code, and keep track of what you were doing when you revisit code in the future
# a.)
# print("hello world")
# Either way here works, I like the '$'
mean(patients101[, 3])
mean(patients101$sysBP)
# b.)
sd(patients101$sysBP)
# c.)
mean(patients101$weight)
# d. )
mean(patients101$height)
# e.)
# The aggregate function allows us to apply a measure of our choosing to subsets of our data, very powerful
aggregate(weight ~ gender, data = patients101, mean)
# f.)
aggregate(height ~ gender, data = patients101, sd)
# g.)
# height "by" marriage,
aggregate(weight ~ marriage, data = patients101, length)
# h.)
aggregate(weight ~ marriage, data = patients101, mean)
