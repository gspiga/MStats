{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2ba0a96",
   "metadata": {},
   "source": [
    "# STA 208: Homework 2 (Do not distribute)\n",
    "\n",
    "## Due 05/12/2023 midnight (11:59pm)\n",
    "\n",
    "__Instructions:__ \n",
    "\n",
    "1. Submit your homework using one file name ”LastName_FirstName_hw2.html” on canvas. \n",
    "2. The written portions can be either done in markdown and TeX in new cells or written by hand and scanned. Using TeX is strongly preferred. However, if you have scanned solutions for handwriting, you can submit a zip file. Please make sure your handwriting is clear and readable and your scanned files are displayed properly in your jupyter notebook. \n",
    "3. Your code should be readable; writing a piece of code should be compared to writing a page of a book. Adopt the one-statement-per-line rule. Consider splitting a lengthy statement into multiple lines to improve readability. (You will lose one point for each line that does not follow the one-statementper-line rule)\n",
    "4. To help understand and maintain code, you should always add comments to explain your code. (homework with no comments will receive 0 points). For a very long comment, please break it into multiple lines.\n",
    "5. In your Jupyter Notebook, put your answers in new cells after each exercise. You can make as many new cells as you like. Use code cells for code and Markdown cells for text.\n",
    "6. Please make sure to print out the necessary results to avoid losing points. We should not run your code to figure out your answers. \n",
    "7. However, also make sure we are able to open this notebook and run everything here by running the cells in sequence; in case that the TA wants to check the details.\n",
    "8. You will be graded on correctness of your math, code efficiency and succinctness, and conclusions and modelling decisions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6525107",
   "metadata": {},
   "source": [
    "### Exercise 1 (Logistic regression)\n",
    "\n",
    "(15 points) In class, we studied the logit model with 2 classes. Now consider the multilogit model with $K$ classes. Let $\\beta$ be the $(p+1)(K-1)$-vector consisting of all the coefficients. Define a suitably enlarged version of the input vector x to accomodate this vectorized coefficient matrix. Derive the Newton-Raphson algorithm for maximizing the multinomial log-likelihood, and describe how you implement the algorithm (e.g., you can write a sudo code). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f02eaca",
   "metadata": {},
   "source": [
    "### Exercise 2 (Support vector machine)\n",
    "\n",
    "_Natural language processing_ (NLP) is a branch of artificial intelligence which gives computers the ability to learn text and spoken words in much the same way human beings can.\n",
    "\n",
    "In python, text data can be converted into vector data through a vectorization operation.\n",
    "Two vectorizer packages in Python are ``sklearn.feature_extraction.text.CountVectorizer`` and ``sklearn.feature_extraction.text.TfidfVectorizer``. A corpus is a collection of documents and the dictionary is all of the words in the corpus. A simple vectorizer will let $X_{i,j}$ be the number of times the $j$th word is in the $i$th document. \n",
    "\n",
    "Bag-of-words models is one of the most popular model in NLP. The model treats each document as a set of words but ignoring the order of those words. \n",
    "\n",
    "In this exercise, you will learn how to classify a text using SVM. The dataset includes two CSV files (`Corona_NLP_train.csv` and `Corona_NLP_test.csv`) that contain IDs and sentiment scores of the tweets related to the COVID-19 pandemic. The real-time Twitter feed is monitored for coronavirus-related tweets using 90+ different keywords and hashtags that are commonly used while referencing the pandemic. The oldest tweets in this dataset date back to October 01, 2019. \n",
    "\n",
    "\n",
    "The training dataset contains five columns: \n",
    "- UserName\t\n",
    "- ScreenName\t\n",
    "- Location\t\n",
    "- TweetAt\t\n",
    "- OriginalTweet\t\n",
    "- Sentiment (five labels: `extremely positive`, `positive`, `negative`, `extremely negative`, `neutral`)\n",
    "\n",
    "The task is to predict sentiment basedon the original tweet. Here, we combine `extremely positive` and `positive` to `positive` and combine `extremely negative` and `negative` to `negative`. So, the sentiment contains three labels.\n",
    "Your goal is to apply svm to predict the three labels based on OriginalTweet. Indeed, one can view this as a classification problem with three labels. \n",
    "\n",
    "I already attached the file `dataprocessing.ipynb` for processing the data. The code is directly copied from this [website](https://www.kaggle.com/code/mehmetlaudatekman/text-classification-svm-explained/notebook).\n",
    "\n",
    "Please answer the following questions:\n",
    " \n",
    "1. (15 points) Use sklearn svm.SVC on the TRAIN split (`Corona_NLP_train.csv`) and predict on the TEST split (`Corona_NLP_test.csv`). Plot your ROC and PR (Precision-Recall) curves for predicting `positive` (versus everything else); use the linear kernel and set the C parameter to be 1. Do the same for predicting the `negative` label versus everything else. Please write the code for generating the ROC curve by yourself.\n",
    "2. (10 points) In this problem, we have three labels (instead of two). In class, we only learned SVM for solving a two-class classification problem. Describe (using your own words) how the python package `svm.SVC` fits SVM for multi-class classification.\n",
    "3. (10 points) Choose several different values for $C$ (some are smaller than 1, some are bigger than 1), plot the ROC curves for predicting 'positive' (versus everything else), and predicting 'negative' (versus everything else). Comment on your findings. \n",
    "4. (Bonus 10 points) Explore how to use logistic regression to classify this text. Implement the method. Comment on its prediction accuracy and compare the ROC curve with the SVM ROC curve. \n",
    "\n",
    "__Note:__ the PR curve is a ratio of the number of true positives divided by the sum of the true positives and false positives. It describes how good a model is at predicting the positive class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519aba15",
   "metadata": {},
   "source": [
    "### Exercise 3 (K-means and PCA)\n",
    "\n",
    "Load the poses.csv dataset, which is a concatenation of other datasets to form a larger dataset. The task column in the dataset contains six poses: sitting, lying, walking, standing, cycling, bending. I want you to act like the dataset is from the same experiment. You need to open the file and take a look the dataset first. Combining bending1 and bending2 together. \n",
    "\n",
    "1. (15 pts) Apply 1 time lag difference of the dataset, so that each variable is the difference of the time point and the previous time point.  Standardize the dataset and remove any variables that do not make sense.  Run the PCA decomposition with 2 principal components.  Plot the 2 principal components.  Which variables have the most loading on the principal components (look at `.components_`)?\n",
    "\n",
    "1. (15 pts) Also on the 1 lagged dataset.  Run K-means clustering (with 6 clusters), how much does the cluster overlap with the 'task' variable.  Look at the confusion matrix (`sklearn.metrics.confusion_matrix`) of the cluster against the 'task'.  Is there a clear mapping from clusters to task?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
