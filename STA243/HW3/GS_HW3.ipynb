{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xf but this version of numpy is 0xe",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;31mRuntimeError\u001b[0m: module compiled against API version 0xf but this version of numpy is 0xe"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "initialization failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.multiarray failed to import",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mSystemError\u001b[0m: <built-in method __contains__ of dict object at 0x00000248223D2A40> returned a result with an error set",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_32396/3703304695.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#from keras.datasets import mnist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpress\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtyping\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_typing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_pywrap_tensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;31m# pylint: enable=wildcard-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\context.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tfe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmonitoring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\client\\pywrap_tf_session.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# pylint: disable=invalid-import-order,g-bad-import-order, wildcard-import, unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pywrap_tf_session\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pywrap_tf_session\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_TF_SetTarget\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pywrap_tf_session\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_TF_SetConfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: initialization failed"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "#from keras.datasets import mnist\n",
    "import plotly.express as px\n",
    "from IPython.display import display\n",
    "\n",
    "from scipy import sparse\n",
    "from skimage.measure import block_reduce "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_55476/2958566322.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"mnist.npz\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#mnist.load_data()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m60000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m60000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data(path=\"mnist.npz\") #mnist.load_data()\n",
    "assert x_train.shape == (60000, 28, 28)\n",
    "assert x_test.shape == (10000, 28, 28)\n",
    "assert y_train.shape == (60000,)\n",
    "assert y_test.shape == (10000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30596, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Get all the values whos true classification is less than 5\n",
    "y_train_i = np.nonzero(y_train < 5)[0]\n",
    "# Find those grids in x_train\n",
    "#display(x_train.shape)\n",
    "x_train = x_train[y_train_i]\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "        16.  , 130.  , 168.5 , 169.  , 168.5 ,  63.  ,   0.  ,   0.  ,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ,   0.  ,  62.75, 233.5 , 201.75,\n",
       "       119.5 ,  92.5 , 224.75, 221.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "         0.  ,   2.5 , 113.  , 244.  ,  93.5 ,   0.  ,   0.  ,   0.  ,\n",
       "       130.25, 252.5 ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,  84.5 ,\n",
       "       252.5 , 180.75,  11.75,   0.  ,   0.  ,   0.  , 191.75, 165.75,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ,  84.25, 246.25, 202.25,  21.75,\n",
       "         0.  ,   0.  ,   0.  ,  28.5 , 231.5 ,  36.25,   0.  ,   0.  ,\n",
       "         0.  ,   0.  , 229.  , 236.25, 246.25,  35.5 ,   0.  ,   0.  ,\n",
       "         1.75, 176.  , 130.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "       174.5 , 205.25, 102.75,   0.  ,   0.  ,   0.  , 131.25, 146.75,\n",
       "        14.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  , 109.5 ,\n",
       "       210.75, 250.25, 252.5 , 253.25, 183.75,   0.  ,   0.  ,   0.  ,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,  53.75,\n",
       "        97.5 ,  86.  ,   3.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(example[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "x: %{x}<br>y: %{y}<br>color: %{z}<extra></extra>",
         "name": "0",
         "type": "heatmap",
         "xaxis": "x",
         "yaxis": "y",
         "z": [
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           51,
           159,
           253,
           159,
           50,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           48,
           238,
           252,
           252,
           252,
           237,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           54,
           227,
           253,
           252,
           239,
           233,
           252,
           57,
           6,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           10,
           60,
           224,
           252,
           253,
           252,
           202,
           84,
           252,
           253,
           122,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           163,
           252,
           252,
           252,
           253,
           252,
           252,
           96,
           189,
           253,
           167,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           51,
           238,
           253,
           253,
           190,
           114,
           253,
           228,
           47,
           79,
           255,
           168,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           48,
           238,
           252,
           252,
           179,
           12,
           75,
           121,
           21,
           0,
           0,
           253,
           243,
           50,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           38,
           165,
           253,
           233,
           208,
           84,
           0,
           0,
           0,
           0,
           0,
           0,
           253,
           252,
           165,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           7,
           178,
           252,
           240,
           71,
           19,
           28,
           0,
           0,
           0,
           0,
           0,
           0,
           253,
           252,
           195,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           57,
           252,
           252,
           63,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           253,
           252,
           195,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           198,
           253,
           190,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           255,
           253,
           196,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           76,
           246,
           252,
           112,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           253,
           252,
           148,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           85,
           252,
           230,
           25,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           7,
           135,
           253,
           186,
           12,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           85,
           252,
           223,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           7,
           131,
           252,
           225,
           71,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           85,
           252,
           145,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           48,
           165,
           252,
           173,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           86,
           253,
           225,
           0,
           0,
           0,
           0,
           0,
           0,
           114,
           238,
           253,
           162,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           85,
           252,
           249,
           146,
           48,
           29,
           85,
           178,
           225,
           253,
           223,
           167,
           56,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           85,
           252,
           252,
           252,
           229,
           215,
           252,
           252,
           252,
           196,
           130,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           28,
           199,
           252,
           252,
           253,
           252,
           252,
           233,
           145,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           25,
           128,
           252,
           253,
           252,
           141,
           37,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ]
         ]
        }
       ],
       "layout": {
        "coloraxis": {
         "colorscale": [
          [
           0,
           "rgb(0, 0, 0)"
          ],
          [
           0.09090909090909091,
           "rgb(16, 16, 16)"
          ],
          [
           0.18181818181818182,
           "rgb(38, 38, 38)"
          ],
          [
           0.2727272727272727,
           "rgb(59, 59, 59)"
          ],
          [
           0.36363636363636365,
           "rgb(81, 80, 80)"
          ],
          [
           0.45454545454545453,
           "rgb(102, 101, 101)"
          ],
          [
           0.5454545454545454,
           "rgb(124, 123, 122)"
          ],
          [
           0.6363636363636364,
           "rgb(146, 146, 145)"
          ],
          [
           0.7272727272727273,
           "rgb(171, 171, 170)"
          ],
          [
           0.8181818181818182,
           "rgb(197, 197, 195)"
          ],
          [
           0.9090909090909091,
           "rgb(224, 224, 223)"
          ],
          [
           1,
           "rgb(254, 254, 253)"
          ]
         ]
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "scaleanchor": "y"
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "constrain": "domain",
         "domain": [
          0,
          1
         ]
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(px.imshow(x_train[0], color_continuous_scale='gray'))\n",
    "\n",
    "def image_compression(mat):\n",
    "    n = mat.shape[0] # 28\n",
    "    new = np.zeros(shape = (int(n/2), int(n/2)))\n",
    "    display(mat.shape)\n",
    "    for i in range(0, n, 2):\n",
    "        display(mat[np.ix_([i, i+1], [i, i+1])])\n",
    "        val = np.mean(mat[np.ix_([i, i+1], [i, i+1])])\n",
    "        new[i//2, i//2] = val\n",
    "        #for j in range(i, i+):\n",
    "\n",
    "    # flatten the matrix by stacking columns \n",
    "    #new = new.flatten(order = \"F\")\n",
    "    return new\n",
    "\n",
    "\n",
    "def image_comp(data, flatten = False):\n",
    "    ### Can compress image either into 14x14 or 196x1\n",
    "    ### Regardless, scaled by 255\n",
    "    if flatten == True:\n",
    "        new_red = np.zeros((data.shape[0], 196))\n",
    "        for i in range(data.shape[0]):\n",
    "            new_red[i]  = block_reduce(data[i, :, :], block_size = (2,2), func = np.mean).flatten(order = \"F\")/255\n",
    "    else:\n",
    "        new_red = np.zeros((data.shape[0], 14, 14))\n",
    "        for i in range(data.shape[0]):\n",
    "            new_red[i]  = block_reduce(data[i, :, :], block_size = (2,2), func = np.mean)/255\n",
    "\n",
    "    return new_red\n",
    "    \n",
    "x_train_comp = image_comp(x_train, flatten = True)\n",
    "#px.imshow(example[0])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My prod is  [ 5.37478993e-11 -6.56227665e-11 -5.72782856e-11 ... -2.21619151e-11\n",
      " -8.62300598e-11 -3.97590740e-11]\n",
      "My prod is  [ 7.50878080e-11 -1.25388044e-10 -3.97007662e-11 ... -7.78764092e-11\n",
      " -1.74742331e-10  7.77902229e-13]\n",
      "My prod is  [ 4.45215333e-11 -3.78038291e-11 -3.90955680e-11 ...  3.19114729e-11\n",
      " -4.18238582e-11 -1.52268175e-11]\n",
      "My prod is  [ 5.42098629e-11 -6.96892100e-11 -8.43377061e-12 ... -3.67575599e-11\n",
      " -8.07649575e-11  2.25271202e-11]\n",
      "My prod is  [ 3.20320865e-11  4.10801720e-12 -2.64095892e-11 ...  6.15643319e-11\n",
      " -8.61118363e-12 -5.38006516e-11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gianni\\anaconda3\\lib\\site-packages\\numpy\\linalg\\linalg.py:2154: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in det\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "My new Sigma is,  [[[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "nan\n",
      "My new Sigma is,  [[[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "nan\n",
      "My new Sigma is,  [[[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "nan\n",
      "My new Sigma is,  [[[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "nan\n",
      "My new Sigma is,  [[[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "nan\n",
      "My new Sigma is,  [[[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "nan\n",
      "My new Sigma is,  [[[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "nan\n",
      "My new Sigma is,  [[[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "nan\n",
      "My new Sigma is,  [[[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "nan\n",
      "My new Sigma is,  [[[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]]\n",
      "My prod is  [ 1.04674367e-11 -1.06869093e-11 -5.81523241e-12 ... -4.84673561e-11\n",
      " -2.05326644e-11 -2.23813953e-11]\n",
      "My prod is  [ 3.94825015e-11 -1.57828257e-10 -1.00381307e-10 ... -1.23847539e-10\n",
      " -1.84702007e-10  4.32071153e-11]\n",
      "My prod is  [ 2.88044633e-12  3.20082228e-12  1.90944022e-11 ... -1.03234563e-11\n",
      " -2.96024003e-12  2.04367593e-11]\n",
      "My prod is  [-8.38229763e-11  8.58723025e-11  5.39313065e-11 ...  8.38498825e-11\n",
      "  1.08910949e-10 -7.90922465e-11]\n",
      "My prod is  [ 3.90469642e-12 -8.63957983e-11 -8.61799333e-11 ... -7.68882462e-11\n",
      " -1.31812631e-10 -1.19612797e-11]\n",
      "nan\n",
      "My new Sigma is,  [[[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "nan\n",
      "My new Sigma is,  [[[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "nan\n",
      "My new Sigma is,  [[[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "nan\n",
      "My new Sigma is,  [[[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "nan\n",
      "My new Sigma is,  [[[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "nan\n",
      "My new Sigma is,  [[[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "nan\n",
      "My new Sigma is,  [[[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "nan\n",
      "My new Sigma is,  [[[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "nan\n",
      "My new Sigma is,  [[[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "nan\n",
      "My new Sigma is,  [[[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]]\n",
      "My prod is  [-1.08893553e-11 -3.71029071e-11 -1.42229250e-11 ...  1.33476144e-11\n",
      " -5.63158113e-12  7.06423582e-12]\n",
      "My prod is  [-1.55869843e-11 -1.11232383e-10 -5.99254148e-11 ... -1.03070104e-10\n",
      " -1.37769695e-10  2.45575960e-11]\n",
      "My prod is  [-9.76057448e-11  1.58864210e-10  4.37442102e-11 ...  7.31000935e-11\n",
      "  1.68081642e-10 -9.87784736e-12]\n",
      "My prod is  [-2.84907422e-11  1.18485761e-10  8.80523364e-11 ...  1.08591997e-10\n",
      "  1.84161897e-10 -1.93135058e-11]\n",
      "My prod is  [-3.99875995e-11  9.32358974e-11  1.25582431e-11 ...  4.87425956e-11\n",
      "  7.69933503e-11 -3.11136222e-11]\n",
      "nan\n",
      "My new Sigma is,  [[[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "nan\n",
      "My new Sigma is,  [[[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "nan\n",
      "My new Sigma is,  [[[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "nan\n",
      "My new Sigma is,  [[[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "nan\n",
      "My new Sigma is,  [[[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "nan\n",
      "My new Sigma is,  [[[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "nan\n",
      "My new Sigma is,  [[[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "nan\n",
      "My new Sigma is,  [[[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "nan\n",
      "My new Sigma is,  [[[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "My prod is  [nan nan nan ... nan nan nan]\n",
      "nan\n",
      "My new Sigma is,  [[[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]\n",
      "  [nan nan nan nan nan]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan]]),\n",
       " array([[[nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan]],\n",
       " \n",
       "        [[nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan]],\n",
       " \n",
       "        [[nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan]],\n",
       " \n",
       "        [[nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan]],\n",
       " \n",
       "        [[nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan]]]),\n",
       " array([nan, nan, nan, nan, nan]))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have five clusters\n",
    "# We do not know which image it belongs to (K-means) but EM can help us figure it out by using mixture of gaussians\n",
    "import gc\n",
    "gc.collect()\n",
    "#import silence_tensorflow.auto\n",
    "\n",
    "#import tensorflow_probability as tfp \n",
    "\n",
    "from tqdm import tqdm # progress meter\n",
    "\n",
    "def mlt_norm(x, mu, Sigma, log = True):\n",
    "    # Dimensions ( not)\n",
    "    k = len(mu)  \n",
    "    # Find the constant\n",
    "    constant = 1.0 / (np.sqrt((2 * np.pi) ** k * np.linalg.det(Sigma)))\n",
    "    # Exponent term\n",
    "    exponent = -0.5 * np.dot(np.dot((x - mu).T, np.linalg.inv(Sigma)), (x - mu))\n",
    "    likelihood = constant * np.exp(exponent)\n",
    "\n",
    "    # a little if-else for the log \n",
    "    if log == True:\n",
    "        return np.log(likelihood)\n",
    "    else:\n",
    "        return likelihood\n",
    "\n",
    "\n",
    "def em(data, n_classes, n_initializations, n_iterations, random_seed = 1001, sigma = \"spherical\", tol = 0.0001):\n",
    "    #Set seed for reproducible results\n",
    "    np.random.seed(random_seed)\n",
    "    n_samples = data.shape[0] # Should be 30596 \n",
    "    \n",
    "\n",
    "    for initializations in range(n_initializations):\n",
    "        # We estabilish our parameters with random generation, n_classes = clusters \n",
    "        # We initialize our parmaeters\n",
    "        # Mu will be random sample of 5 rows from the 30,000+ rows, could do K-means but defeats the purpose\n",
    "        mu = data[np.random.randint(data.shape[1], size = 5), :] #5 x 196\n",
    "        \n",
    "        if sigma == \"spherical\":\n",
    "            # For the spherical case, we can take the average of all the variances of the 196 columns in the data, and apply that to an identity matrix\n",
    "            var_avg = np.mean(np.var(data, axis = 1))\n",
    "            Sigma = var_avg * np.eye(data.shape[1]) # Covariance matrix of the entire data set\n",
    "            Sigma = np.repeat(Sigma[:, :, np.newaxis], n_classes, axis = 2)\n",
    "            #print(Sigma[:,:,0])\n",
    "        if sigma == \"diagonal\":\n",
    "            # For the spherical case, we can take the average of all the variances of the 196 columns in the data, and apply that to an identity matrix\n",
    "            var_avg = np.mean(np.var(data, axis = 1))\n",
    "            Sigma = var_avg * np.eye(data.shape[1]) # Covariance matrix of the entire data set\n",
    "\n",
    "        # For pi, we can use Dirichlet since it sums to 1\n",
    "        pi = np.random.dirichlet(np.ones(n_classes))\n",
    "\n",
    "\n",
    "        for iteration in range(n_iterations):\n",
    "            # Declare likelihoods\n",
    "            new_likelihood = -np.inf\n",
    "            old_likelihood = -np.inf\n",
    "\n",
    "            # E-Step\n",
    "            Fij = np.zeros((n_samples, n_classes))\n",
    "            ### To speed up complexity, we are going to try a tensor approach \n",
    "            ### We will do x - uj 5 times and save them into a tensor, this way we save ourselves redoing the calculation for each iteration\n",
    "            tensor_calc = np.zeros((n_samples, data.shape[1], n_classes)) # 30596 x 196 x 5\n",
    "            d = data.shape[1]\n",
    "            for t in range(n_classes):\n",
    "                x_mu = sparse.csr_matrix(data - mu[t,:]) # x - mu_j\n",
    "                \n",
    "                # First half \n",
    "                inv_sigma = sparse.csr_matrix(np.diag(1/np.diag(Sigma[:,:,t])))\n",
    "                half = x_mu @ inv_sigma\n",
    "                half = half.todense()\n",
    "                product = np.einsum('ij,ji->i', half, x_mu.todense().T) # Only need the diagonal entries\n",
    "                Fij[:,t] = pi[t]*np.log(1.0 / (np.sqrt((2 * np.pi) ** d * Sigma[:,:,t].diagonal().prod()))) + -0.5 *product \n",
    "                \n",
    "            # To normalize, we divide each entry in a row of Fij by its row sum\n",
    "            for j_prime in range(Fij.shape[0]):\n",
    "                Fij[j_prime, :] /= Fij[j_prime, :].sum(keepdims = True)\n",
    "\n",
    "            #print(\"Fij after normalization\", Fij)\n",
    "\n",
    "            # M step\n",
    "            # Updating rules\n",
    "            # pi and mu can be done outside of a loop\n",
    "            pi = np.mean(Fij, axis = 0)\n",
    "            mu = Fij.T @ data / np.sum(Fij, axis =0).reshape(-1,1)\n",
    "            for col in range(n_classes):\n",
    "                # Updating rules       \n",
    "                x_mu = data - mu[col,:]\n",
    "                prod = (Fij[:,col] @ (x_mu) @ (x_mu).T)\n",
    "                #print(\"My prod is \", prod)\n",
    "                Sigma[:,:, col] = prod.sum() / Fij[:,col].sum() \n",
    "                Sigma[:,:,col] = np.fill_diagonal(Sigma[:,:,col], Sigma[:,:,col].diagonal() + 0.05) # per hint provided \n",
    "            new_likelihood = mlt_norm(data[0,:], mu[0,:], Sigma[:,:,0])\n",
    "            #print(new_likelihood)\n",
    "\n",
    "            if np.abs(new_likelihood - old_likelihood)/old_likelihood < tol:\n",
    "                break\n",
    "            print(\"My new Sigma is, \", Sigma)\n",
    "                \n",
    "    return mu, Sigma, pi\n",
    "    \n",
    "em(x_train_comp, 5, 3, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
