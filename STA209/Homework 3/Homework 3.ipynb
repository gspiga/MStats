{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3\n",
    "\n",
    "## Gianni Spiga\n",
    "\n",
    "### For STA 209, Fall 2023\n",
    "\n",
    "- I discussed approaches and methodology to these problems with Jonas Kempf and Niraj Bangari "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Assume set $V \\subset \\mathbb{R}^n$ is a nonempty convex set. Remember that according to the definition, a set is convex when\n",
    "\n",
    "$$\n",
    "\\text{For all} \\ x,y \\in V, \\ \\text{and for all} \\ 0 \\leq \\ \\alpha \\leq1 \\ \\text{we have} \\alpha x + (1 - \\alpha)y \\in V\n",
    "$$\n",
    "\n",
    " - (a) **Shifting a convex set** For $x_0 \\in \\mathbb{R}^n$, define\n",
    "$$\n",
    "W = x_0 + V := \\{x \\in \\mathbb{R}^n : x = x_0 + v \\ \\text{for some} \\ v \\in V\\}.\n",
    "$$\n",
    "\n",
    "We can define two points, $\\lambda_1, \\lambda_2 \\in W$, defined as the following:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\lambda_1 = x_0 + v_1 \\\\\n",
    "\\lambda_2 = x_0 + v_2 \\\\ \n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\alpha \\lambda_1 + (1 - \\alpha) \\lambda_2 &= \\alpha (x_0 + v_1) + (1 - \\alpha) (x_0 + v_2) \\\\\n",
    "&= \\alpha x_0 + \\alpha v_1 + (1 - \\alpha) x_0 + (1 - \\alpha) v_2 \\\\\n",
    "&= \\alpha x_0 + (1 - \\alpha) x_0 + \\alpha v_1 + (1 - \\alpha) v_2 \\\\\n",
    "&= x_0 + \\alpha v_1 + (1 - \\alpha) v_2 \\\\ \n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "We can see $\\lambda_1, \\lambda_2 \\in W$ can be expressed as a convex set for $\\forall \\alpha, 0 \\leq \\alpha \\leq 1$\n",
    "\n",
    "\n",
    "- (b) **Scaling a convex set** For $\\lambda \\in \\mathbb{R}^n$, define\n",
    "$$\n",
    "W = \\lambda V := \\{x \\in \\mathbb{R}^n : x = \\lambda v  \\ \\text{for some} \\ v \\in V \\} .\n",
    "$$\n",
    "\n",
    "We can define two points, $\\gamma_1, \\gamma_2 \\in W$, defined as the following:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\gamma_1 = \\lambda v_1 \\\\\n",
    "\\gamma_2 = \\lambda v_2 \\\\ \n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\alpha \\gamma_1 + (1 - \\alpha) \\gamma_2 &= \\alpha (\\lambda v_1) + (1 - \\alpha) (\\lambda v_2) \\\\\n",
    "&= \\lambda \\big(\\alpha v_1 + (1 - \\alpha) v_2 \\big)\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "We can see $\\gamma_1, \\gamma_2 \\in W$ can be expressed as a convex set for $\\forall \\alpha, 0 \\leq \\alpha \\leq 1$\n",
    "\n",
    "- (c) Union of convex sets Let V ′ be another nonempty convex set. Define\n",
    "$$\n",
    "W = V \\cup V' = \\{x \\in \\mathbb{R}^n : x \\in V \\text{or} \\ x \\in V'\\} \n",
    "$$\n",
    "\n",
    "Let $\\lambda_1 \\in V$ and $\\lambda_2 \\in V'$. The union of two convex sets is can not always be convex. If the line/hyperplane connecting the two points leaves the set, then the union is not convex. \n",
    "\n",
    "- (d) Intersection of convex sets. Let V ′ be another nonempty convex set. Define\n",
    "$$\n",
    "W = V \\cap V' = \\{x \\in \\mathbb{R}^n: x \\in V \\ \\text{and} \\ x \\in V' \\}\n",
    "$$\n",
    "\n",
    "Let $x_1, x_2 \\in W$, Since $W$ is the intersection of two convex points. Thus:\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\alpha x_1 + (1 - \\alpha) x_2 &\\in V, V' \\\\\n",
    "\\alpha x_1 + (1 - \\alpha) x_2 &\\in V \\cap V' \\\\\n",
    "\\alpha x_1 + (1 - \\alpha) x_2 &\\in W\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Hence $W$ is convex. \n",
    "\n",
    "- (e) **Halfspaces** For a vector $a \\in \\mathbb{R}^n$ and $b \\in \\mathbb{R}$, define\n",
    "$$\n",
    "W = \\{x \\in \\mathbb{R}^n : a^Tx \\geq b \\}\n",
    "$$\n",
    "\n",
    "We can define two points, $\\lambda_1, \\lambda_2 \\in W$, we need to show:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "a^T(\\alpha \\lambda_1 + (1 - \\alpha) \\lambda_2) &\\geq b \\\\\n",
    "a^T(\\alpha \\lambda_1 + (1 - \\alpha) \\lambda_2) &= \\alpha (a^T \\lambda_1) + (1 - \\alpha) (a^T \\lambda_2) \\\\\n",
    "&= \\alpha (a^T \\lambda_1) + (1 - \\alpha) (a^T \\lambda_2) \\\\\n",
    "&\\geq \\alpha (b) + (1 - \\alpha) (b) \\\\\n",
    "&\\geq (\\alpha  + 1 - \\alpha) b \\\\\n",
    "&\\geq b \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "The half space can be represented as a convex set. \n",
    "\n",
    "- (f) Polyhedron For matrix $A \\in \\mathbb{R}^{m x n}$ and vector $b \\in \\mathbb{R}^m$, define\n",
    "$$\n",
    "W = \\{x \\in \\mathbb{R}^n : Ax \\geq b\\}\n",
    "$$\n",
    "where the inequality over vectors is defined elementwise, i.e., for two vectors c and\n",
    "$d \\in \\mathbb{R}^m$ we say $c \\leq d$ when $c_i \\leq d_i$ for all $i$.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "A(\\alpha \\lambda_1 + (1 - \\alpha) \\lambda_2) &= \\alpha (A \\lambda_1) + (1 - \\alpha) (A \\lambda_2) \\\\\n",
    "&\\geq \\alpha (b) + (1 - \\alpha) (b) \\\\\n",
    "&\\geq b\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "The set is convex.\n",
    "\n",
    "- (g) **Ellipsoid** Given a symmetric positive definite matrix $H \\in \\mathbb{R}^{n x n}$ (i.e., where all the\n",
    "eigenvalues are positive) and a vector $x_0 \\in \\mathbb{R}^n$, define\n",
    "$$\n",
    "W = \\{x \\in \\mathbb{R}^n : (x - x_0)^T P^{-1}(x - x_0) \\leq 5\\} \n",
    "$$\n",
    "\n",
    "We define two points from $W$, $\\lambda_1, \\lambda_2 \\in \\mathbb{R}^n$. We then have:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "(\\alpha \\lambda_1 + (1 - \\alpha) \\lambda_2 - x_0)^T P^{-1}(\\alpha \\lambda_1 + (1 - \\alpha) \\lambda_2 - x_0) \n",
    "&= (\\alpha (\\lambda_1 - x_0) + (1 - \\alpha) (y - x_0))^T P^{-1} (\\alpha (\\lambda_1 - x_0) + (1 - \\alpha) (\\lambda_2 - x_0)) \\\\\n",
    "&= (\\alpha (\\lambda_1 - x_0))^T P^{-1} (\\alpha (\\lambda_1 - x_0)) + (\\alpha (\\lambda_1 - x_0))^T P^{-1} ((1 - \\alpha) (\\lambda_2 - x_0)) \\\\\n",
    "&\\quad + ((1 - \\alpha) (\\lambda_2 - x_0))^T P^{-1} (\\alpha (\\lambda_1 - x_0)) + ((1 - \\alpha) (\\lambda_2 - x_0))^T P^{-1} ((1 - \\alpha) (\\lambda_2 - x_0)) \\\\\n",
    "&= \\alpha^2 (\\lambda_1 - x_0)^T P^{-1} (\\lambda_1 - x_0) + \\alpha(1 - \\alpha) (\\lambda_1 - x_0)^T P^{-1} (\\lambda_2 - x_0) \\\\\n",
    "&\\quad + \\alpha(1 - \\alpha) (\\lambda_2 - x_0)^T P^{-1} (\\lambda_1 - x_0) + (1 - \\alpha)^2 (\\lambda_2 - x_0)^T P^{-1} (\\lambda_2 - x_0)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Since $P$ is positive definite, $P^{-1}$ is also positive definite. Since each term in the expression is quadratic, we will always have the expression is greater than 0. Along with this, our expression is now in the form of the convex equation, showing that our ellipsoid is indeed a convex set. \n",
    "\n",
    "-(h) Given a symmetric negative definite matrix $H \\in \\mathbb{R}^{n x n}$ (i.e., where all the\n",
    "eigenvalues are negative) and a vector $x_0 \\in \\mathbb{R}^n$, define\n",
    "$$\n",
    "W = \\{x \\in \\mathbb{R}^n : (x - x_0)^T P^{-1}(x - x_0) \\leq 5\\} \n",
    "$$\n",
    "\n",
    "We define two points $\\lambda_1, \\lambda_2 \\in \\mathbb{R}^n$. We then have:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "(\\alpha \\lambda_1 + (1 - \\alpha) \\lambda_2 - x_0)^T P^{-1}(\\alpha \\lambda_1 + (1 - \\alpha) \\lambda_2 - x_0) \n",
    "&= (\\alpha (\\lambda_1 - x_0) + (1 - \\alpha) (y - x_0))^T P^{-1} (\\alpha (\\lambda_1 - x_0) + (1 - \\alpha) (\\lambda_2 - x_0)) \\\\\n",
    "&= (\\alpha (\\lambda_1 - x_0))^T P^{-1} (\\alpha (\\lambda_1 - x_0)) + (\\alpha (\\lambda_1 - x_0))^T P^{-1} ((1 - \\alpha) (\\lambda_2 - x_0)) \\\\\n",
    "&\\quad + ((1 - \\alpha) (\\lambda_2 - x_0))^T P^{-1} (\\alpha (\\lambda_1 - x_0)) + ((1 - \\alpha) (\\lambda_2 - x_0))^T P^{-1} ((1 - \\alpha) (\\lambda_2 - x_0)) \\\\\n",
    "&= \\alpha^2 (\\lambda_1 - x_0)^T P^{-1} (\\lambda_1 - x_0) + \\alpha(1 - \\alpha) (\\lambda_1 - x_0)^T P^{-1} (\\lambda_2 - x_0) \\\\\n",
    "&\\quad + \\alpha(1 - \\alpha) (\\lambda_2 - x_0)^T P^{-1} (\\lambda_1 - x_0) + (1 - \\alpha)^2 (\\lambda_2 - x_0)^T P^{-1} (\\lambda_2 - x_0)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Since $P$ is negative definite, $P^{-1}$ is also negative definite. Since each term in the expression is quadratic, we will always have the expression is less than 0, showing that our ellipsoid is not a convex set. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. A function $f : \\mathbb{R}^n \\rightarrow \\mathbb{R}$ is called convex if\n",
    "$$\n",
    "\\begin{equation}\n",
    "f (αx + (1 − α)y) ≤ αf (x) + (1 − α)f (y)\n",
    "\\end{equation}\n",
    "$$\n",
    "holds for all $x, y ∈ \\text{dom}(f )$ and $α ∈ [0, 1]$. A function $f : \\mathbb{R}^n \\rightarrow \\mathbb{R}$  is called $m$-strongly\n",
    "convex if\n",
    "$$\n",
    "\\begin{equation}\n",
    "f (αx + (1 − α)y) ≤ αf (x) + (1 − α)f (y) − \\frac{m}{2} α(1 − α)||x − y||^2 \\\\\n",
    "\\end{equation}\n",
    "$$\n",
    "holds for all $x, y ∈ \\text{dom}(f )$ and $α ∈ [0, 1]$. In each of the following cases, determine whether\n",
    "the statement is true or not. Justify your answer with a proof or a counter example.\n",
    "\n",
    "- (a)  non-negative weighted sum of convex functions $(f_1, \\ldots , f_m)$,\n",
    "$$\n",
    "f = w_1f_1 + \\ldots + w_mf_m\n",
    "$$\n",
    "is convex.\n",
    "\n",
    "We definite two points in the domain of $f$: $\\lambda_1, \\lambda_2$. We show:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "f(\\alpha \\lambda_1 + (1 - \\alpha)\\lambda_2) &= w_1f_1(\\alpha \\lambda_1 + (1 - \\alpha)\\lambda_2) + w_2f_2(\\alpha \\lambda_1 + (1 - \\alpha)\\lambda_2) + \\ldots + w_mf_m(\\alpha \\lambda_1 + (1 - \\alpha)\\lambda_2) \\\\\n",
    "&\\leq w_1[\\alpha f_1(\\lambda_1) + (1 - \\alpha)f_1(\\lambda_2)] + w_2[\\alpha f_2(\\lambda_1) + (1 - \\alpha)f_2(\\lambda_2)] + \\ldots + w_m[\\alpha f_m(\\lambda_1) + (1 - \\alpha)f_m(\\lambda_2)] \\\\\n",
    "&= \\alpha [w_1f_1(\\lambda_1) + w_2f_2(\\lambda_1) + \\ldots + w_mf_m(\\lambda_1)] + (1 - \\alpha)[w_1f_1(\\lambda_2) + w_2f_2(\\lambda_2) + \\ldots + w_mf_m(\\lambda_2)] \\\\\n",
    "&= \\alpha f(\\lambda_1) + (1 - \\alpha) f(\\lambda_2)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Thus the function is convex. \n",
    "\n",
    "- (b) Let $g, h :\\mathbb{R}^n \\rightarrow \\mathbb{R}$ be two convex functions, then $f = g − h$ is convex.\n",
    "\n",
    "We can think of a simple counter example, have $g(x) = x^4$ and $h(x) = 4x^4$. We then would have $f(x) = -3x^4$, which would not be convex. Thus by contradiction, the subtraction of two convex functions can not always result in a convex function.\n",
    "\n",
    "- (c) Let $g :\\mathbb{R}^n \\rightarrow \\mathbb{R}$ be a convex function and $h :\\mathbb{R}^n \\rightarrow \\mathbb{R}$ be a linear function, then $f = g − h$ is convex. \n",
    "\n",
    "Like the previous question...\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "(g - h)(\\alpha x + (1 - \\alpha)y) &\\leq \\alpha(g - h)(x) + (1 - \\alpha)(g - h)(y) \\\\ \n",
    "g(\\alpha x + (1 - \\alpha)y) - h(\\alpha x + (1 - \\alpha)y) &\\leq \\alpha[g(x) - h(x)] + (1 - \\alpha)[g(y) - h(y)] \\\\\n",
    "\\text{By convexity of $g$ and linearity of $h$, we have}& \\\\\n",
    "g(\\alpha x + (1 - \\alpha)y) \\leq \\alpha g(x) + (1 - \\alpha) g(y) \\\\\n",
    "h(\\alpha x + (1 - \\alpha)y) = \\alpha h(x) + (1 - \\alpha) h(y) \\\\\n",
    "\\text{Which we can plug in respectively}& \\\\\n",
    "\\left[\\alpha g(x) + (1 - \\alpha) g(y)\\right] - \\left[\\alpha h(x) + (1 - \\alpha) h(y)\\right] &\\leq  \\\\\n",
    "\\alpha g(x) + (1 - \\alpha) g(y) - \\alpha h(x) - (1 - \\alpha) h(y) &\\leq \\\\\n",
    "\\alpha[g(x) - h(x)] + (1 - \\alpha)[g(y) - h(y)] &\\leq\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Since the terms are equal, this inequality is true. Thus we have satisfied the condition for convexity and the subtraction of a linear function from a  convex function is convex. \n",
    "\n",
    "- (d) Let $g, h :\\mathbb{R}^n \\rightarrow \\mathbb{R}$ be $m_1$ and $m_2$ strongly convex functions, then $f = g +h$ is $m_1 +m_2$\n",
    "strongly convex function.\n",
    "\n",
    "As shown before:\n",
    "$$\n",
    "f(\\alpha x + (1 - \\alpha)y) = (g + h)(\\alpha x + (1 - \\alpha)y) = g(\\alpha x + (1 - \\alpha)y) + h(\\alpha x + (1 - \\alpha)y)\n",
    "$$\n",
    "\n",
    "For our respective functions, we then have: \n",
    "$$\n",
    "\\begin{align*}\n",
    "g(\\alpha x + (1 - \\alpha)y) &\\leq \\alpha g(x) + (1 - \\alpha)g(y) - \\frac{m_1}{2}\\alpha(1 - \\alpha)\\|x - y\\|^2 \\\\\n",
    "h(\\alpha x + (1 - \\alpha)y) &\\leq \\alpha h(x) + (1 - \\alpha)h(y) - \\frac{m_2}{2}\\alpha(1 - \\alpha)\\|x - y\\|^2 \\\\\n",
    "\\text{We now add both sides of the inequality:} \\\\\n",
    "g(\\alpha x + (1 - \\alpha)y) + h(\\alpha x + (1 - \\alpha)y) &\\leq \\alpha g(x) + (1 - \\alpha)g(y) - \\frac{m_1}{2}\\alpha(1 - \\alpha)\\|x - y\\|^2 + \\alpha h(x) + (1 - \\alpha)h(y) - \\frac{m_2}{2}\\alpha(1 - \\alpha)\\|x - y\\|^2 \\\\\n",
    "&\\leq \\alpha[g(x) + h(x)] + (1 - \\alpha)[g(y) + h(y)] - \\big(\\frac{m_1}{2} + \\frac{m_2}{2}\\big)\\alpha(1 - \\alpha)\\|x - y\\|^2 \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "We can see we have now simplified our expression to match the format of the definition of a strongly convex function, replacing $m$ with $m_1 + m_2$ for the addition of two strongly convex functions. \n",
    "\n",
    "- (e) Suppose $f : \\mathbb{R}^n \\rightarrow \\mathbb{R}$, $A ∈ \\mathbb{R}^{n×m}$, and $b ∈ \\mathbb{R}^n$. Define $g: \\mathbb{R}^m \\rightarrow \\mathbb{R}$ by\n",
    "$$\n",
    "g(x) = f (Ax + b)\n",
    "$$\n",
    "with $\\text{dom} g = \\{x | Ax + b ∈ \\text{dom} f \\}$. Then if $f$ is convex, so is $g$;\n",
    "\n",
    "We can say two points, $\\lambda_1, \\lambda_2 \\in \\text{dom} g $ where $\\lambda_1 = f (Ax + b)$ and $\\lambda_2 = f(Ay + b)$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "f(\\alpha (Ax + b) + (1 - \\alpha)(Ay + b)) &\\leq \\alpha f(Ax + b) + (1 - \\alpha) f(Ay + b) \\\\\n",
    "g(\\alpha \\lambda_1 + (1 - \\alpha)\\lambda_2) &\\leq \\alpha g(\\lambda_1) + (1 - \\alpha) g(\\lambda_2) \\\\ \n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Since we can represent the function $g$ satisfiying the convexity condition for any points $\\lambda_1, \\lambda_2$, we have proved that if the function $f$ is convec, then $g$ as defined above, is also convex. \n",
    "\n",
    "- (f) If $f_1$ and $f_2$ are convex functions then their pointwise maximum $f$, defined by\n",
    "$$\n",
    "f (x) = \\max \\{f_1(x), f_2(x)\\}\n",
    "$$\n",
    "with $\\text{dom} f = \\text{dom} f_1 \\cap \\text{dom} f_2$, is also convex.\n",
    "\n",
    "We want to show:\n",
    "$$\n",
    "f (αx + (1 − α)y) ≤ αf (x) + (1 − α)f (y)\n",
    "$$\n",
    "\n",
    "We substitute:\n",
    "$$\n",
    "\\begin{align*}\n",
    "f (αx + (1 − α)y) &\\leq α \\max \\{f_1(x), f_2(x)\\} + (1 − α)\\max \\{f_1(y), f_2(y)\\} \\\\\n",
    "\\text{Since the maximum function is upperbounded }& \\text{by its own arguments, we have the two inequalities} \\\\\n",
    "f_1(αx + (1 − α)y)&\\leq α f(x)\\ + (1 − α)f(y) \\\\\n",
    "&\\text{and}\\\\\n",
    "f_2(αx + (1 − α)y)&\\leq α f(x)\\ + (1 − α)f(y) \\\\\n",
    "&\\text{Thus we have} \\\\\n",
    "f (αx + (1 − α)y) \\leq \\max\\{&f_1(αx + (1 − α)y), f_2(αx + (1 − α)y) \\} \\leq α f(x)\\ + (1 − α)f(y) \\\\\n",
    "f (αx + (1 − α)y) &\\leq α f(x)\\ + (1 − α)f(y) \n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Thus the max function is convex. \n",
    "\n",
    "- (g) If $f_1$ and $f_2$ are convex functions then their pointwise maximum $f$, defined by\n",
    "$$\n",
    "f (x) = \\min \\{f_1(x), f_2(x)\\}\n",
    "$$\n",
    "with $\\text{dom} f = \\text{dom} f_1 \\cap \\text{dom} f_2$, is also convex.\n",
    "\n",
    "Take two quadratic equations, say $f_1(x) = x^2$ and $f_2(x) = (x - 3)^2$. With this condition, $f(0) = 0, f(3) = 0$, however at $f(1) = 1$, we solve at $\\alpha = 0.5$:\n",
    "$$\n",
    "f (αx + (1 − α)y) ≤ αf (x) + (1 − α)f (y) \\\\\n",
    "f(0.5 * 0 + 0.5 * 1) \\leq 0.5 * 1 + \n",
    "$$\n",
    " \n",
    "The minimum function is not convex everywhere, as we could have two quadratic functions where the graph of the minimum (which would be a $w$ shape) would have a line connecting the two points leaving the convex set of the quadratic functions, thus not being convex. \n",
    "\n",
    "- (h) Let $C$ be a convex subset of $\\mathbb{R}^n$, $b$ be a number in $\\mathbb{R}$, and let $F = \\{f_i | f_i : C −→ R, i ∈ I\\}$\n",
    "be a family of convex functions such that $f_i(x) \\leq b$ for every $i ∈ I$ and $x ∈ C$. Then,\n",
    "the function $f : C −→ \\mathbb{R}$ defined by\n",
    "$$\n",
    "f (x) = \\sup \\{f_i(x) | i ∈ I\\}\n",
    "$$\n",
    "for $x ∈ C$ is a convex function.\n",
    "\n",
    "We show:\n",
    "$$\n",
    "\\begin{align*}\n",
    "f (αx + (1 − α)y) &≤ αf (x) + (1 − α)f (y) \\\\\n",
    "&\\text{We have for each $i$:} \\\\\n",
    "f_i(\\alpha x+(1-\\alpha)y)\\leq \\alpha f_i(x)+&(1-\\alpha)f_i(y)\\leq \\alpha f(x)+(1-\\alpha)f(y) \\\\\n",
    "&\\text{Taking the supremum of the left side to find:} \\\\\n",
    "f &(\\alpha x+(1-\\alpha)y)\\leq \\leq \\alpha f(x)+(1-\\alpha)f(y) \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Thus the supremum is convex. \n",
    "\n",
    "- (i) If $f$ is convex in $(x, y)$, and $C$ is a convex nonempty set, then\n",
    "$$\n",
    "g(x) = \\inf_{y∈C} f (x, y)\n",
    "$$\n",
    "\n",
    "is convex in $x$, provided $g(x) > −\\infty$ for all $x$ and\n",
    "$$\n",
    "\\text{dom} \\ g = \\{x | (x, y) ∈ \\text{dom} f \\ \\text{for some} \\ y ∈ C \\}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "g(\\alpha x_1 + (1 - \\alpha) x_2) \\leq f( \\alpha x_1 + (1 - \\alpha) x_2,\\alpha y_1 + (1 - \\alpha)y_2) \\\\\n",
    "g(\\alpha x_1 + (1 - \\alpha) x_2)  \\leq \\alpha f(x_1,y_1) + (1 - \\alpha) f(x_2,y_2) \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Thus the infinum is convex.\n",
    "\n",
    "- (j) The epigraph $\\text{epi}(f )$ of a function $f : \\mathbb{R}^n \\rightarrow \\mathbb{R}$ is a subset of $\\mathbb{R}^{n+1}$ defined by\n",
    "$$\n",
    "\\text{epi}(f ) = \\{(x, t) | x ∈ \\text{dom}(f ), f (x) ≤ t\\}\n",
    "$$\n",
    "Let $f : S −→ \\mathbb{R}$ be a function defined on the convex subset $S$ of $\\mathbb{R}^n$. Then, $f$ is\n",
    "convex on $S$ if and only if its epigraph is a convex subset of $S × \\mathbb{R}$.\n",
    "\n",
    "**Forward**:  For points $(x, t_1), (y, t_2)$:\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{We show the line segment that belongs to the epigraph as:}&\n",
    "f (\\alpha x + (1 − \\alpha )y) &\\leq \\alpha t_1 + (1 − \\alpha ) t_2 \\\\\n",
    "f (\\alpha x + (1 − \\alpha )y) &\\leq \\alpha f(x) + (1 − \\alpha ) f(y)  &\\leq \\alpha t_1 + (1 − \\alpha ) t_2 \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Thus $text{epi}(f)$ is convex by convexity of $f$. \n",
    "\n",
    "**Backward** If $text{epi}(f)$ is convex, then for points $(x, f(x)), (y, f(y))$, the segment that connects the two must also be in the epigraph. \n",
    "$$\n",
    "(\\alpha x + (1 - \\alpha)y, \\alpha f(x) + (1 - \\alpha) f(y)) \\in \\text{epi}(f)\n",
    "$$\n",
    "\n",
    "Thus $f$ must be convex for the two points are connected by a line within a convex epigraph. \n",
    "\n",
    "- (k) If $f : \\mathbb{R}^n → \\mathbb{R}$, then the perspective of $f$ is the function $g :mathbb{R}^{n+1} → \\mathbb{R} defined by\n",
    "$$\n",
    "g(x, t) = tf (x/t)\n",
    "$$\n",
    "with domain\n",
    "$$\n",
    "\\text{dom} \\ g = \\{(x, t) | x/t ∈ \\text{dom} \\ f, t > 0\\}\n",
    "$$\n",
    "The perspective operation preserves convexity: If $f$ is a convex function, then so is\n",
    "its perspective function $g$.\n",
    "\n",
    "With two points $(x_1, t_1)$ and $(x_2, t_2)$ in the domain of $g$, where $x_1/t_1$ and $x_2/t_2$ are in the domain of $f$ and $t_1 > 0$, $t_2 > 0$, we can show:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "g(\\alpha x_1 + (1 - \\alpha) x_2, \\alpha t_1 + (1 - \\alpha) t_2) &\\leq \\alpha g(x_1, t_1) + (1 - \\alpha) g(x_2, t_2) \\\\ \n",
    "g(\\alpha x_1 + (1 - \\alpha) x_2, \\alpha t_1 + (1 - \\alpha) t_2) &= (\\alpha t_1 + (1 - \\alpha) t_2) \\cdot f\\left(\\frac{\\alpha x_1 + (1 - \\alpha) x_2}{\\alpha t_1 + (1 - \\alpha) t_2}\\right) \\\\\n",
    "&\\text{and} \\\\\n",
    "\\alpha g(x_1, t_1) + (1 - \\alpha) g(x_2, t_2) &= \\alpha(t_1 \\cdot f(x_1/t_1)) + (1 - \\alpha)(t_2 \\cdot f(x_2/t_2)) \\\\\n",
    "&= \\alpha t_1 \\cdot f(x_1/t_1) + (1 - \\alpha) t_2 \\cdot f(x_2/t_2) \\\\\n",
    "&\\text{we have} \\\\\n",
    "f\\left(\\frac{\\alpha x_1 + (1 - \\alpha) x_2}{\\alpha t_1 + (1 - \\alpha) t_2}\\right) &\\leq \\alpha f\\left(\\frac{x_1}{t_1}\\right) + (1 - \\alpha) f\\left(\\frac{x_2}{t_2}\\right) \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Thus the function is convex.\n",
    "\n",
    " - (l) Suppose that $ f : \\mathbb{R} \\rightarrow \\mathbb{R}$ is differentiable function and $f$ is monotonically increasing\n",
    "continuous on \\mathbb{R}, then\n",
    "$$\n",
    "g(x) = \\int_{-\\infty}^x f (t)dt\n",
    "$$\n",
    "is convex function.\n",
    "\n",
    "We first take the derivative, and then taking the second derivative:\n",
    "$$\n",
    "\\begin{align*}\n",
    "g'(x) = \\frac{d}{dx} \\int_{-\\infty}^x f (t)dt \\\\\n",
    "g'(x) =  f (x) \\\\\n",
    "g''(x) =  f'(x) \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "The second derivative of $g$ is the first derivative of $f$, which is a monotonically increasing function $\\geq 0$, thus $g(x)$ is convex. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Let $A$ be an $N × d$ matrix, and consider following functions\n",
    "$$\n",
    "\\begin{align*}\n",
    "f (x) &= \\frac{1}{N} ||Ax − b \\|^2_2 \\\\\n",
    "g (x) &= \\frac{1}{N} \\|Ax − b \\|^2_2 + \\lambda \\|x \\|^2_2, \\lambda > 0\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "- (a) Compute $\\nabla f(x)$ and $\\nabla g(x)$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\nabla f(x) &= \\frac{d}{dx} \\bigg( \\frac{1}{N} (Ax − b)^T(Ax − b) \\bigg) \\\\\n",
    "&= \\frac{2}{N} (A)^T(Ax − b) \\\\\n",
    "\\nabla g(x) &= \\frac{2}{N} (A)^T(Ax − b) + 2 \\lambda x \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "- (b) Compute $\\nabla^2 f(x)$ and $\\nabla^2 g(x)$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\nabla^2 f(x) &=  \\frac{2}{N} (A)^TA \\\\\n",
    "\\nabla^2 g(x) &= \\frac{2}{N} (A)^TA + 2 \\lambda I \n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "- (c) If $\\text{rank}(A) = d$, show that $f(x)$ and $g(x)$ are convex. \n",
    "\n",
    "\n",
    "Assuming $N \\geq d$, since $A^TA$ is full rank, all eigenvalues will be positive, meaning $\\nabla^2 f(x)$ is positive definite, thus $f(x)$ is convex. To extend $g(x)$, $2\\lambda I$ ust be positive, which it always will be since $\\lambda > 0$, thus $\\nabla^2 g(x)$ is positive definite and $g(x)$ is convex. \n",
    "\n",
    "- (d) If $\\text{rank}(A) = d$, check if $f(x)$ and $g(x)$ are strongly convex. If they are, find the\n",
    "strong convexity parameter $m$ for them.\n",
    "\n",
    "For $f(x)$, since we know is $A^TA$ is full rank and positive definite, the positive lower bound $m = \\min(\\lambda)$ (the smallest eigenvalue). Since all eigenvalues are postive, $f(x)$ is strongly convex. \n",
    "\n",
    "For $g(x)$, since we know the Hessian is the sum of two positive definite matrices, $m = \\min_{\\lambda_e} (\\frac{2}{N}A^TA, 2 \\lambda I)$ the minimum eigenvalue from the two matrices. Thus $g(x)$ is strongly convex. \n",
    "\n",
    "- (e) If $\\text{rank}(A) = d$, check if $f(x)$ and $g(x)$ are smooth. If they are, find the smoothness\n",
    "parameter $L$ for them.\n",
    "\n",
    "For $f(x)$, since we know is $A^TA$ is full rank and positive definite, the Lipschitz constant would be the largest eigenvalue of $L_f = \\frac{2}{N}\\lambda_{max}$.\n",
    "\n",
    "For $g(x)$, since we know the Hessian is postive definite, as an extension of $f(x)$, the Lipschitz constant would be the $L_g = \\frac{2}{N}\\lambda_{max} + 2\\lambda$.\n",
    "\n",
    "- (f) If $\\text{rank}(A) < d$ check if $f(x)$ and $g(x)$ are convex, and also check if $f(x)$ and $g(x)$ are strongly convex. \n",
    "\n",
    "Since $\\text{rank}(A) < d$, $A^TA$ is not full rank, which means the Hessian is not positive definite/ eigenvalues equal to $0$. Thus neither $f(x)$ nor $g(x)$ are convex nor strongly-convex. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. For given scalars $y_i in \\mathbb{R}$ and vectors $a_i \\in \\mathbb{R}^d for $i = 1, \\ldots , N$ , consider the logistic\n",
    "regression loss function\n",
    "$$\n",
    "f (x) = \\frac{1}{N} \\sum_{i =1}^N \\log(1 + e^{-y_i〈x_i a_i〉})\n",
    "$$\n",
    "\n",
    "- (a) Prove that $f(x)$ is convex\n",
    "\n",
    "From the previous homework, we found the $\\nabla f(x) = \\frac{- y_i x_i\\exp\\{−y_i a_i^T x_i\\}}{1 + \\exp\\{−y_i a_i^T x_i\\}}$ and $\\nabla^2 f(x) = \\frac{y_i^2 \\exp\\{−y_i a_i^T x_i\\}}{\\big(1 + \\exp\\{−y_i a_i^T x_i\\}\\big)^2} a_i a_i^T$\n",
    "\n",
    "Since the $\\nabla^2 f(x)$ is positive semi-definite, we can conclude convexity. \n",
    "\n",
    "- (b) Let $h_i : \\mathbb{R}^d \\rightarrow \\mathbb{R}$ be a twicely differentiable and $L_i$-smooth for $i = 1, .\\ldots , N$ . Prove\n",
    "that $\\frac{1}{N} \\sum_{i =1}^N h_i(x)$ is $\\sum_{i =1}^n \\frac{L}{N}$-smooth. \n",
    "\n",
    "We check the Hessian\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\lambda \\max(\\nabla h_i(x)) \\leq L_i \\\\\n",
    "\\lambda \\max(\\sum_{i =1}^N h_i(x)) &\\leq \\frac{1}{N}  \\sum_{i =1}^N \\lambda \\max(\\nabla^2 h_i(x)) \\\\\n",
    "&\\leq \\frac{1}{N}  \\sum_{i =1}^N L_i\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "- (c) Use result in (b) to show $f (x)$ is L-smooth and find the smoothness constant.\n",
    "\n",
    "Since we have $N$ functions of $h(x)$, which are each $L_i$-smooth, thus the function $f(x)$ $L = \\sum_{i=1}^N L_i$. \n",
    "\n",
    "- (d) Let $L_{\\phi} > 0$ be a positive constant. Let $g(x) = \\frac{1}{N} \\sum_{i =1}^N \\phi_i (a_i^T x)$ where $\\phi_i: \\mathbb{R} \\rightarrow \\mathbb{R}$ is a\n",
    "scalar function such that $|φ_i^{''} (t)| ≤ L_φ$ for all $t ∈ \\mathbb{R}$. Prove that $g(x)$ is $\\frac{L_{\\phi}}{N} \\lambda_{max}(A^TA)$-smooth where the $i$-th row of $A$ is $a_i^T$. With this result, can you find a better estimate of the smoothness constant of the logistic regression loss?\n",
    "\n",
    "First we find the Hessian \n",
    "$$\n",
    "\\begin{align*}\n",
    "g(x) &= \\frac{1}{N} \\sum_{i =1}^N \\phi_i (a_i^T x) \\\\\n",
    "\\nabla^2 g(x) &= \\frac{1}{N} \\phi_i^{''} (a_i^T x) (a_i a_i^T) \\\\ \n",
    "& \\leq  \\frac{1}{N} \\sum^N_{i =1} (a_i a_i^T) \\\\ \n",
    "& \\leq \\frac{L_{\\phi}}{N} A^T A\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "$\\leq \\frac{L_{\\phi}}{N} A^T A$ is a  positive semi-definite Hessian. To find the $L$ parameter for smoothness, we can find the maximum eigenvalue of $A^TA$. Thus the function g(x) is $L_g$-smooth where $L_g = \\frac{L_{\\phi}}{N} \\lambda_{max}(A^T A)$. Finding a better estimate would be challenging without knowing more about the function $phi$. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the function $f : \\mathbb{R}^n \\rightarrow \\mathbb{R} defined as\n",
    "$$\n",
    "f(x) = a + c^T x + \\frac{L}{2} \\|x\\|^2\n",
    "$$\n",
    "for some $a ∈ \\mathbb{R}$, $L > 0$ and $c ∈ \\mathbb{R}^n$.\n",
    "\n",
    "- (a) Determine the minimmum $min_{x \\in \\mathbb{R}^n} f(x)$ and the minimizer $x∗ = \\arg \\min_{x∈\\mathbb{R}^n} f(x)$ in\n",
    "terms of $a, L$ and $c$.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\nabla f(x) &= c + Lx \\\\\n",
    "0 &= c + Lx*\n",
    "x* &= -\\frac{c}{L}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Now we find the minimum value of $f$ at $x*$\n",
    "$$\n",
    "\\begin{align*}\n",
    "f(x*) &= a + c^T x* + \\frac{L}{2} \\|x*\\|^2 \\\\\n",
    "&= a + c^T -\\frac{c}{L} + \\frac{L}{2} \\|-\\frac{c}{L}\\|^2 \\\\\n",
    "&= a - \\frac{c^Tc}{L} + \\frac{L}{2} \\|-\\frac{c}{L}\\|^2 \\\\\n",
    "\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "- (b) Consider the vector $x_0 \\in \\mathbb{R}^n$. We want to move from $x_0$ in the direction of $\\Delta \\in \\mathbb{R}^n$\n",
    "such that $x_1 = x_0 + \\Delta$ is the minimizer of the function $f$ . What is the value of vector\n",
    "$\\Delta$ that satisfies this property? Determine $\\Delta$ in terms of the parameter $L$ and $\\nabla f(x_0)$.\n",
    "\n",
    "From the previous problem, we found minimizing point $x*$, we now want to move in the direction of $\\Delta$, thus:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\Delta &= x* - x_0 \\\\\n",
    "&= -\\frac{c}{L} - x_0 \\\\\n",
    "&\\text{We also have} \\\\\n",
    "\\nabla f(x_0) &= c + Lx_0 \\\\\n",
    "x_0 &= \\frac{1}{L}(\\nabla f(x_0) - c) \\\\\n",
    "&\\text{We now have} \\\\\n",
    "\\Delta &= -\\frac{c}{L} - \\frac{1}{L}(\\nabla f(x_0) - c) \\\\\n",
    "&= -\\frac{c}{L} (\\nabla f(x_0)) \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
