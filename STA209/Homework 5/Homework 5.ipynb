{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5\n",
    "\n",
    "## Gianni Spiga\n",
    "\n",
    "### For STA 209, Fall 2023\n",
    "\n",
    "- I discussed approaches and methodology to these problems with "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Gradient descent without strong convexity\n",
    "Let $f$ be a convex function that is $L$-smooth, but not strongly convex. Instead, assume that the $f(x_0)$ - sublevel set of $f$ is bounded, i.e.\n",
    "$$\n",
    "∀x ∈ \\mathbb{R}^n \\ \\text{such that} \\ f(x) ≤ f (x^0) , \\ \\|x − x_0 \\| ≤ R_0 /2\n",
    "$$\n",
    "As long as the function values $f(x^k)$ decrease as the algorithm proceeds, our iterates $x^k$ will never be farther than $\\mathbb{R}_0$ from $x^∗$. [Show that using triangle inequality]. Remark 4.1. We will start with showing the statement that the iterates xk will never be farther than $\\mathbb{R}_0$ from $x^∗$. Let $x_k ∈ \\mathbb{R}^n$ be one iterate such that $f(x^k) < f(x^0)$. Note that as the minimal point, $x^∗$ should also satisfy $f (x^∗) < f (x^{(0)})$. Therefore, it follows from triangle\n",
    "inequality that \n",
    "$$\n",
    "\\| x^k − x^∗ \\|^2 ≤ \\|x^k − x^0 \\|_2 + \\|x^* - x^0\\|_2 \\leq \\frac{R_0}{2} + \\frac{R_0}{2} = R_0\n",
    "$$\n",
    "\n",
    "(a) Show that by optimizing\n",
    "$$\n",
    "f_λ(x) = f(x) + \\frac{λ}{2} \\|x − x^0 \\|^2\n",
    "$$\n",
    "which is $λ + L$-smooth and $λ$-strongly convex and carefully choosing the value of λ, we can\n",
    "find an $\\epsilon$-suboptimal point after poly (1/$\\epsilon$) iterations. What should you set $λ$ to? What\n",
    "is the resulting runtime?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
